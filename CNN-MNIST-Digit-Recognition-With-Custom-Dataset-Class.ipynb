{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72cde1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T05:11:06.709606Z",
     "iopub.status.busy": "2025-02-03T05:11:06.709265Z",
     "iopub.status.idle": "2025-02-03T05:11:13.752887Z",
     "shell.execute_reply": "2025-02-03T05:11:13.752166Z"
    },
    "papermill": {
     "duration": 7.047706,
     "end_time": "2025-02-03T05:11:13.754705",
     "exception": false,
     "start_time": "2025-02-03T05:11:06.706999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Check Which Device is Available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8aa7af5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T05:11:13.759606Z",
     "iopub.status.busy": "2025-02-03T05:11:13.759256Z",
     "iopub.status.idle": "2025-02-03T05:11:13.765305Z",
     "shell.execute_reply": "2025-02-03T05:11:13.764733Z"
    },
    "papermill": {
     "duration": 0.00967,
     "end_time": "2025-02-03T05:11:13.766529",
     "exception": false,
     "start_time": "2025-02-03T05:11:13.756859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train Dataset Custom Class\n",
    "class CustomTrainDataset(Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(path, header='infer').values\n",
    "        self.length = self.data.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        flatimage = self.data[idx, 1:].astype(np.uint8)\n",
    "        image = self.transform(np.reshape(flatimage, (28,28,1)))\n",
    "        label = self.data[idx,0]\n",
    "        return image,label\n",
    "\n",
    "#Test Dataset Custom Class\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(path, header='infer').values\n",
    "        self.length = self.data.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        flatimage = self.data[idx,:].astype(np.uint8)\n",
    "        image = self.transform(np.reshape(flatimage, (28,28,1)))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a103856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T05:11:13.770582Z",
     "iopub.status.busy": "2025-02-03T05:11:13.770367Z",
     "iopub.status.idle": "2025-02-03T05:11:17.751332Z",
     "shell.execute_reply": "2025-02-03T05:11:17.750618Z"
    },
    "papermill": {
     "duration": 3.98466,
     "end_time": "2025-02-03T05:11:17.752925",
     "exception": false,
     "start_time": "2025-02-03T05:11:13.768265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prepare the Datasets \n",
    "train_dataset = CustomTrainDataset('/kaggle/input/digit-recognizer/train.csv', ToTensor())\n",
    "test_dataset = CustomTestDataset('/kaggle/input/digit-recognizer/test.csv', ToTensor())\n",
    "\n",
    "#Define Batch Size\n",
    "batch_size=64\n",
    "\n",
    "#Initialize the Dataloader\n",
    "train_dl=DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dl=DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99aeb7dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T05:11:17.757676Z",
     "iopub.status.busy": "2025-02-03T05:11:17.757448Z",
     "iopub.status.idle": "2025-02-03T05:13:03.106506Z",
     "shell.execute_reply": "2025-02-03T05:13:03.105586Z"
    },
    "papermill": {
     "duration": 105.35313,
     "end_time": "2025-02-03T05:13:03.108156",
     "exception": false,
     "start_time": "2025-02-03T05:11:17.755026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 1\n",
      "Batch: 1 / 657 Running Loss: 2.35 Running Accuracy: 12.5\n",
      "Batch: 101 / 657 Running Loss: 0.32 Running Accuracy: 90.33\n",
      "Batch: 201 / 657 Running Loss: 0.2 Running Accuracy: 93.71\n",
      "Batch: 301 / 657 Running Loss: 0.16 Running Accuracy: 94.98\n",
      "Batch: 401 / 657 Running Loss: 0.14 Running Accuracy: 95.7\n",
      "Batch: 501 / 657 Running Loss: 0.13 Running Accuracy: 96.11\n",
      "Batch: 601 / 657 Running Loss: 0.11 Running Accuracy: 96.43\n",
      "Training: Epoch Loss: 0.11 Epoch Accuracy: 96.56\n",
      "--------------------------------------------------\n",
      "Epoch No: 2\n",
      "Batch: 1 / 657 Running Loss: 0.1 Running Accuracy: 96.88\n",
      "Batch: 101 / 657 Running Loss: 0.05 Running Accuracy: 98.55\n",
      "Batch: 201 / 657 Running Loss: 0.04 Running Accuracy: 98.59\n",
      "Batch: 301 / 657 Running Loss: 0.04 Running Accuracy: 98.63\n",
      "Batch: 401 / 657 Running Loss: 0.04 Running Accuracy: 98.59\n",
      "Batch: 501 / 657 Running Loss: 0.04 Running Accuracy: 98.57\n",
      "Batch: 601 / 657 Running Loss: 0.04 Running Accuracy: 98.58\n",
      "Training: Epoch Loss: 0.04 Epoch Accuracy: 98.58\n",
      "--------------------------------------------------\n",
      "Epoch No: 3\n",
      "Batch: 1 / 657 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.02 Running Accuracy: 99.06\n",
      "Batch: 201 / 657 Running Loss: 0.03 Running Accuracy: 99.0\n",
      "Batch: 301 / 657 Running Loss: 0.03 Running Accuracy: 98.94\n",
      "Batch: 401 / 657 Running Loss: 0.03 Running Accuracy: 98.91\n",
      "Batch: 501 / 657 Running Loss: 0.03 Running Accuracy: 98.93\n",
      "Batch: 601 / 657 Running Loss: 0.03 Running Accuracy: 98.94\n",
      "Training: Epoch Loss: 0.03 Epoch Accuracy: 98.91\n",
      "--------------------------------------------------\n",
      "Epoch No: 4\n",
      "Batch: 1 / 657 Running Loss: 0.02 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.03 Running Accuracy: 98.93\n",
      "Batch: 201 / 657 Running Loss: 0.03 Running Accuracy: 99.07\n",
      "Batch: 301 / 657 Running Loss: 0.02 Running Accuracy: 99.15\n",
      "Batch: 401 / 657 Running Loss: 0.02 Running Accuracy: 99.17\n",
      "Batch: 501 / 657 Running Loss: 0.02 Running Accuracy: 99.21\n",
      "Batch: 601 / 657 Running Loss: 0.02 Running Accuracy: 99.17\n",
      "Training: Epoch Loss: 0.02 Epoch Accuracy: 99.18\n",
      "--------------------------------------------------\n",
      "Epoch No: 5\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.02 Running Accuracy: 99.41\n",
      "Batch: 201 / 657 Running Loss: 0.02 Running Accuracy: 99.45\n",
      "Batch: 301 / 657 Running Loss: 0.02 Running Accuracy: 99.45\n",
      "Batch: 401 / 657 Running Loss: 0.02 Running Accuracy: 99.45\n",
      "Batch: 501 / 657 Running Loss: 0.02 Running Accuracy: 99.43\n",
      "Batch: 601 / 657 Running Loss: 0.02 Running Accuracy: 99.38\n",
      "Training: Epoch Loss: 0.02 Epoch Accuracy: 99.37\n",
      "--------------------------------------------------\n",
      "Epoch No: 6\n",
      "Batch: 1 / 657 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.02 Running Accuracy: 99.54\n",
      "Batch: 201 / 657 Running Loss: 0.02 Running Accuracy: 99.46\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.51\n",
      "Batch: 401 / 657 Running Loss: 0.02 Running Accuracy: 99.47\n",
      "Batch: 501 / 657 Running Loss: 0.02 Running Accuracy: 99.45\n",
      "Batch: 601 / 657 Running Loss: 0.02 Running Accuracy: 99.39\n",
      "Training: Epoch Loss: 0.02 Epoch Accuracy: 99.4\n",
      "--------------------------------------------------\n",
      "Epoch No: 7\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.5\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.56\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.59\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.53\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.52\n",
      "Batch: 601 / 657 Running Loss: 0.02 Running Accuracy: 99.48\n",
      "Training: Epoch Loss: 0.02 Epoch Accuracy: 99.48\n",
      "--------------------------------------------------\n",
      "Epoch No: 8\n",
      "Batch: 1 / 657 Running Loss: 0.03 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.77\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.69\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.67\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.67\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.64\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.65\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.63\n",
      "--------------------------------------------------\n",
      "Epoch No: 9\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.72\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.75\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.69\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.68\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.64\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.63\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.62\n",
      "--------------------------------------------------\n",
      "Epoch No: 10\n",
      "Batch: 1 / 657 Running Loss: 0.01 Running Accuracy: 98.44\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.6\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.7\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.72\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.69\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.7\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.66\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.65\n",
      "--------------------------------------------------\n",
      "Epoch No: 11\n",
      "Batch: 1 / 657 Running Loss: 0.1 Running Accuracy: 98.44\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.63\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.69\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.67\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.7\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.7\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.66\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.64\n",
      "--------------------------------------------------\n",
      "Epoch No: 12\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.71\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.74\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.74\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.74\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.76\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.77\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.77\n",
      "--------------------------------------------------\n",
      "Epoch No: 13\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.8\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.84\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.83\n",
      "--------------------------------------------------\n",
      "Epoch No: 14\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.57\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.65\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.7\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.7\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.7\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.69\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.7\n",
      "--------------------------------------------------\n",
      "Epoch No: 15\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.74\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.75\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.77\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.78\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.77\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.76\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.74\n",
      "--------------------------------------------------\n",
      "Epoch No: 16\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.89\n",
      "--------------------------------------------------\n",
      "Epoch No: 17\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.81\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.84\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.87\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.85\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.84\n",
      "--------------------------------------------------\n",
      "Epoch No: 18\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.86\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.82\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.82\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.85\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.86\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.87\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.87\n",
      "--------------------------------------------------\n",
      "Epoch No: 19\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.94\n",
      "--------------------------------------------------\n",
      "Epoch No: 20\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.86\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.87\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.83\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.79\n",
      "--------------------------------------------------\n",
      "Epoch No: 21\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.63\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.68\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.69\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.68\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.69\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.72\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.73\n",
      "--------------------------------------------------\n",
      "Epoch No: 22\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.96\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.97\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.98\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.97\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.97\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.97\n",
      "--------------------------------------------------\n",
      "Epoch No: 23\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.99\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.99\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.99\n",
      "--------------------------------------------------\n",
      "Epoch No: 24\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.99\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 100.0\n",
      "--------------------------------------------------\n",
      "Epoch No: 25\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.01 Running Accuracy: 99.77\n",
      "Batch: 201 / 657 Running Loss: 0.01 Running Accuracy: 99.7\n",
      "Batch: 301 / 657 Running Loss: 0.01 Running Accuracy: 99.67\n",
      "Batch: 401 / 657 Running Loss: 0.01 Running Accuracy: 99.63\n",
      "Batch: 501 / 657 Running Loss: 0.01 Running Accuracy: 99.66\n",
      "Batch: 601 / 657 Running Loss: 0.01 Running Accuracy: 99.68\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.69\n",
      "--------------------------------------------------\n",
      "Epoch No: 26\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.87\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.89\n",
      "--------------------------------------------------\n",
      "Epoch No: 27\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.91\n",
      "--------------------------------------------------\n",
      "Epoch No: 28\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.86\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.83\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.86\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.85\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.85\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.86\n",
      "--------------------------------------------------\n",
      "Epoch No: 29\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.95\n",
      "--------------------------------------------------\n",
      "Epoch No: 30\n",
      "Batch: 1 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 657 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 201 / 657 Running Loss: 0.0 Running Accuracy: 99.98\n",
      "Batch: 301 / 657 Running Loss: 0.0 Running Accuracy: 99.98\n",
      "Batch: 401 / 657 Running Loss: 0.0 Running Accuracy: 99.98\n",
      "Batch: 501 / 657 Running Loss: 0.0 Running Accuracy: 99.98\n",
      "Batch: 601 / 657 Running Loss: 0.0 Running Accuracy: 99.99\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.99\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Main CNN Class\n",
    "class DRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu=nn.ReLU()\n",
    "        self.conv1=nn.Conv2d(in_channels=1,out_channels=8, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.bn1=nn.BatchNorm2d(8)\n",
    "        self.mp1=nn.MaxPool2d(kernel_size=(2,2),stride=2,padding=0)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=8,out_channels=16, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.bn2=nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=16,out_channels=32, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv4=nn.Conv2d(in_channels=32,out_channels=64, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "               \n",
    "        self.flatten=nn.Flatten()\n",
    "\n",
    "        self.lin1=nn.Linear(in_features=3136, out_features=10)\n",
    "        self.bn5=nn.BatchNorm1d(num_features=10)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.mp1(x)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x=self.bn2(x)\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.bn3(x)\n",
    "        x=self.relu(x)\n",
    "\n",
    "        x=self.conv4(x)\n",
    "        x=self.bn4(x)\n",
    "        x=self.relu(x)\n",
    "\n",
    "        x=self.flatten(x)\n",
    "\n",
    "        output=self.lin1(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "#Function which is used to train the model for Single Iteration, it is driven by a for Loop\n",
    "def train_one_epoch(dataloader, model,loss_fn, optimizer):\n",
    "    model.train()\n",
    "    track_loss=0\n",
    "    num_correct=0\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        imgs=imgs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        pred=model(imgs)\n",
    "                    \n",
    "        loss=loss_fn(pred,labels)\n",
    "        track_loss+=loss.item()\n",
    "        num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n",
    "        \n",
    "        running_loss=round(track_loss/(i+(imgs.shape[0]/batch_size)),2)\n",
    "        running_acc=round((num_correct/((i*batch_size+imgs.shape[0])))*100,2)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i%100==0:\n",
    "            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n",
    "            \n",
    "    epoch_loss=running_loss\n",
    "    epoch_acc=running_acc\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "#Function which is used to Test the model for Single Iteration, it is driven by a for Loop\n",
    "def eval(dataloader, model,loss_fn, path):\n",
    "    model.eval()\n",
    "    data=pd.read_csv(path)\n",
    "    with torch.no_grad():\n",
    "        for i, imgs in enumerate(dataloader):\n",
    "            imgs=imgs.to(device)\n",
    "            pred=model(imgs)\n",
    "            \n",
    "            pred=torch.argmax(pred,dim=1).type(torch.int).cpu()\n",
    "            data.iloc[i*batch_size:i*batch_size+batch_size ,1]=pred.numpy()\n",
    "    \n",
    "    data.to_csv('submission.csv', index=False)\n",
    "    data.head()\n",
    "            \n",
    "            \n",
    "#Create Object of CNN Class\n",
    "model=DRNN()\n",
    "\n",
    "#Load the Model to Device\n",
    "model=model.to(device)\n",
    "\n",
    "#Define Loss Function and Optimizer\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "lr=0.001\n",
    "optimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "n_epochs=30\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"Epoch No:\",i+1)\n",
    "    train_epoch_loss, train_epoch_acc=train_one_epoch(train_dl,model,loss_fn,optimizer)\n",
    "    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "eval(test_dl, model,loss_fn, '/kaggle/input/digit-recognizer/sample_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 121.133992,
   "end_time": "2025-02-03T05:13:04.640365",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-03T05:11:03.506373",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
